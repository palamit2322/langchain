{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07677c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5cef0",
   "metadata": {},
   "source": [
    "## Vector Store Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86069d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pathlib import Path\n",
    "\n",
    "BASEDIR=Path.cwd()\n",
    "\n",
    "PATHDIR=BASEDIR / \"data\" / \"MachineLearning.pdf\"\n",
    "\n",
    "loader=PyPDFLoader(PATHDIR)\n",
    "docs=loader.load()\n",
    "\n",
    "rec_splitter=RecursiveCharacterTextSplitter(chunk_size=300 ,chunk_overlap=30)\n",
    "\n",
    "chunks=rec_splitter.split_documents(docs)\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c43f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/f5d05_ts38v4p_s_j0zrgq1m0000gn/T/ipykernel_39936/1195941946.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n",
      "/var/folders/tc/f5d05_ts38v4p_s_j0zrgq1m0000gn/T/ipykernel_39936/1195941946.py:9: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"my_docs\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "vectorstore.add_documents(chunks)\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d252c62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "ID:None: tor machine its name.\n",
      "To make a prediction for a new point, the distance to each of the support vectors is\n",
      "measured. A classification decision is made based on the distances to the support vec‚Äê\n",
      "tor, and the importance of the support vectors that was learned during training\n",
      "ID:None: large machine, or even to rent one from a cloud provider. In most applications, the\n",
      "data that is used to build a machine learning system is relatively small, though, and\n",
      "few machine learning datasets consist of hundreds of gigabites of data or more. This\n",
      "ID:None: put given an input. In particular, the algorithm is able to create an output for an input\n",
      "it has never seen before without any help from a human. Going back to our example\n",
      "of spam classification, using machine learning, the user provides the algorithm with a\n"
     ]
    }
   ],
   "source": [
    "vector_retriever=vectorstore.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "response=vector_retriever.invoke(\"machine\")\n",
    "print(len(response))\n",
    "for d in response:\n",
    "    print(f\"ID:{d.metadata.get('id')}: {d.page_content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ad118",
   "metadata": {},
   "source": [
    "## BM25 Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf5ca4",
   "metadata": {},
   "source": [
    "BM25 is a lexical (keyword-based) retrieval algorithm.\n",
    "\n",
    "Matches exact words\n",
    "\n",
    "Uses term frequency + inverse document frequency\n",
    "\n",
    "No embeddings\n",
    "\n",
    "Very fast\n",
    "\n",
    "üëâ Best for:\n",
    "\n",
    "IDs, codes, names\n",
    "\n",
    "Numbers\n",
    "\n",
    "Error messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780c0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'Preface\\nMachine learning is an integral part of many commercial applications and research\\nprojects today, in areas ranging from medical diagnosis and treatment to finding your\\nfriends on social networks. Many people think that machine learning can only be\\napplied by large companies with extensive research teams. In this book, we want to\\nshow you how easy it can be to build machine learning solutions yourself, and how to\\nbest go about it. With the knowledge in this book, you can build your own system for\\nfinding out how people feel on Twitter, or making predictions about global warming.\\nThe applications of machine learning are endless and, with the amount of data avail‚Äê\\nable today, mostly limited by your imagination.\\nWho Should Read This Book\\nThis book is for current and aspiring machine learning practitioners looking to\\nimplement solutions to real-world machine learning problems. This is an introduc‚Äê\\ntory book requiring no previous knowledge of machine learning or artificial intelli‚Äê\\ngence (AI). We focus on using Python and the scikit-learn library, and work\\nthrough all the steps to create a successful machine learning application. The meth‚Äê\\nods we introduce will be helpful for scientists and researchers, as well as data scien‚Äê\\ntists working on commercial applications. Y ou will get the most out of the book if you\\nare somewhat familiar with Python and the NumPy and matplotlib libraries.\\nWe made a conscious effort not to focus too much on the math, but rather on the\\npractical aspects of using machine learning algorithms. As mathematics (probability\\ntheory, in particular) is the foundation upon which machine learning is built, we\\nwon‚Äôt go into the analysis of the algorithms in great detail. If you are interested in the\\nmathematics of machine learning algorithms, we recommend the book The Elements\\nof Statistical Learning  (Springer) by Trevor Hastie, Robert Tibshirani, and Jerome\\nFriedman, which is available for free at the authors‚Äô website. We will also not describe\\nhow to write machine learning algorithms from scratch, and will instead focus on\\nvii'}\n",
      "{'CHAPTER 1\\nIntroduction\\nMachine learning is about extracting knowledge from data. It is a research field at the\\nintersection of statistics, artificial intelligence, and computer science and is also\\nknown as predictive analytics or statistical learning. The application of machine\\nlearning methods has in recent years become ubiquitous in everyday life. From auto‚Äê\\nmatic recommendations of which movies to watch, to what food to order or which\\nproducts to buy, to personalized online radio and recognizing your friends in your\\nphotos, many modern websites and devices have machine learning algorithms at their\\ncore. When you look at a complex website like Facebook, Amazon, or Netflix, it is\\nvery likely that every part of the site contains multiple machine learning models.\\nOutside of commercial applications, machine learning has had a tremendous influ‚Äê\\nence on the way data-driven research is done today. The tools introduced in this book\\nhave been applied to diverse scientific problems such as understanding stars, finding\\ndistant planets, discovering new particles, analyzing DNA sequences, and providing\\npersonalized cancer treatments.\\nY our application doesn‚Äôt need to be as large-scale or world-changing as these exam‚Äê\\nples in order to benefit from machine learning, though. In this chapter, we will\\nexplain why machine learning has become so popular and discuss what kinds of\\nproblems can be solved using machine learning. Then, we will show you how to build\\nyour first machine learning model, introducing important concepts along the way.\\nWhy Machine Learning?\\nIn the early days of ‚Äúintelligent‚Äù applications, many systems used handcoded rules of\\n‚Äúif ‚Äù and ‚Äúelse‚Äù decisions to process data or adjust to user input. Think of a spam filter\\nwhose job is to move the appropriate incoming email messages to a spam folder. Y ou\\ncould make up a blacklist of words that would result in an email being marked as\\n1'}\n",
      "{'how to use the large array of models already implemented in scikit-learn and other\\nlibraries.\\nWhy We Wrote This Book\\nThere are many books on machine learning and AI. However, all of them are meant\\nfor graduate students or PhD students in computer science, and they‚Äôre full of\\nadvanced mathematics. This is in stark contrast with how machine learning is being\\nused, as a commodity tool in research and commercial applications. Today, applying\\nmachine learning does not require a PhD. However, there are few resources out there\\nthat fully cover all the important aspects of implementing machine learning in prac‚Äê\\ntice, without requiring you to take advanced math courses. We hope this book will\\nhelp people who want to apply machine learning without reading up on years‚Äô worth\\nof calculus, linear algebra, and probability theory.\\nNavigating This Book\\nThis book is organized roughly as follows:\\n‚Ä¢ Chapter 1  introduces the fundamental concepts of machine learning and its\\napplications, and describes the setup we will be using throughout the book.\\n‚Ä¢ Chapters 2 and 3 describe the actual machine learning algorithms that are most\\nwidely used in practice, and discuss their advantages and shortcomings.\\n‚Ä¢ Chapter 4 discusses the importance of how we represent data that is processed by\\nmachine learning, and what aspects of the data to pay attention to.\\n‚Ä¢ Chapter 5 covers advanced methods for model evaluation and parameter tuning,\\nwith a particular focus on cross-validation and grid search.\\n‚Ä¢ Chapter 6 explains the concept of pipelines for chaining models and encapsulat‚Äê\\ning your workflow.\\n‚Ä¢ Chapter 7 shows how to apply the methods described in earlier chapters to text\\ndata, and introduces some text-specific processing techniques.\\n‚Ä¢ Chapter 8 offers a high-level overview, and includes references to more advanced\\ntopics.\\nWhile Chapters 2 and 3 provide the actual algorithms, understanding all of these\\nalgorithms might not be necessary for a beginner. If you need to build a machine\\nlearning system ASAP , we suggest starting with Chapter 1 and the opening sections of\\nChapter 2, which introduce all the core concepts. Y ou can then skip to ‚ÄúSummary and\\nOutlook‚Äù on page 127 in Chapter 2, which includes a list of all the supervised models\\nthat we cover. Choose the model that best fits your needs and flip back to read the\\nviii | Preface'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25Retriever=BM25Retriever.from_documents(documents=docs,k=3)\n",
    "\n",
    "response=bm25Retriever.invoke(\"machine\")\n",
    "print(len(response))\n",
    "for d in response:\n",
    "    print({d.page_content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfd5af",
   "metadata": {},
   "source": [
    "## Ensemble /Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4021603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.ensemble import EnsembleRetriever\n",
    "\n",
    "bm25Retriever=BM25Retriever.from_documents(documents=docs,k=3)\n",
    "vector_retriever=vectorstore.as_retriever(search_kwargs={\"k\":3})\n",
    "\n",
    "#Ensemble\n",
    "ensemble=EnsembleRetriever(retrievers=[bm25Retriever,vector_retriever], weights=[0.5,0.5])\n",
    "\n",
    "response=ensemble.invoke(\"machine\")\n",
    "print(len(response))\n",
    "for d in response:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc32627",
   "metadata": {},
   "source": [
    "## MultiQuery Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203140ca",
   "metadata": {},
   "source": [
    "User query: \"machine\"\n",
    "‚Üí Retriever searches using exactly \"machine\"\n",
    "‚Üí Misses synonyms, intent variations\n",
    "\n",
    "LLM rewrites the query into multiple variants:\n",
    "- \"machine learning concepts\"\n",
    "- \"types of machines in AI\"\n",
    "- \"how machines learn\"\n",
    "\n",
    "Each query ‚Üí retriever ‚Üí results merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=base_retriever,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "docs = multi_query_retriever.invoke(\"machine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f422329d",
   "metadata": {},
   "source": [
    "## Contextual compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280a72c",
   "metadata": {},
   "source": [
    "Problem in normal RAG\n",
    "\n",
    "Retriever returns long chunks\n",
    "\n",
    "Only 2‚Äì3 lines are relevant\n",
    "\n",
    "LLM wastes tokens + hallucinations\n",
    "\n",
    "Solution\n",
    "\n",
    "Compress retrieved documents based on the user query\n",
    "\n",
    "üëâ Keep only query-relevant sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b867ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# LLM for compression\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Base retriever (vector)\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# Compressor\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# Contextual Compression Retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")\n",
    "\n",
    "docs = compression_retriever.invoke(\"machine learning types\")\n",
    "\n",
    "print(\"Compressed docs:\", len(docs))\n",
    "for d in docs:\n",
    "    print(\"\\n---\")\n",
    "    print(d.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
